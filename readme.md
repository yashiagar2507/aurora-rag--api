ğŸš€ Aurora RAG Question Answering API

A lightweight Retrieval-Augmented Generation (RAG) system that answers natural language questions about Aurora members by retrieving and reasoning over their messages from the /messages API.

ğŸ§© Overview

This service accepts a natural-language question such as:

â€œWhen is Layla planning her trip to London?â€
â€œHow many cars does Vikram Desai have?â€
â€œWhat are Fatimaâ€™s favorite restaurants?â€

and returns a grounded, AI-generated answer inferred from real message data.

âš™ï¸ Tech Stack

FastAPI â€“ for serving the API

Sentence-Transformers â€“ for dense embeddings

FAISS â€“ for similarity search

Anthropic Claude â€“ for reasoning and language generation

Python 3.10 â€“ runtime environment

ğŸ§  Bonus 1: Design Notes
B) RAG (Retrieval-Augmented Generation) with dense embeddings âœ… (Chosen)
How it works:

Fetch all messages from /messages.

Split them into smaller text chunks.

Convert each chunk into an embedding (vector of numbers) using Sentence-Transformers.

Store all embeddings inside a FAISS index for fast similarity search.

When the user asks a question:

The system retrieves the top relevant chunks from FAISS.

These chunks, plus the question, are sent to the Claude model (Anthropic) to generate the answer.

Pros

âœ… Gives grounded answers based on real data.
âš¡ Scales well for large message sets.
ğŸ’° Cheaper than sending all data to the model every time.
ğŸ§± Embeddings can be cached for speed.

Cons

âš™ï¸ Needs an embedding step and light storage.
ğŸ§© Requires prompt tuning for consistent answers.

Why chosen:
This approach provides the best balance of accuracy, cost efficiency, and engineering simplicity for the assignment.

ğŸ” Bonus 2: Data Insights

After exploring the /messages dataset, a few issues were observed:

Issue	Description
ğŸŒ€ Duplicate entries	Some messages appear multiple times, leading to redundancy.
ğŸ“… Mixed date formats	Dates appear both as â€œMarch 3â€ and â€œ2025-03-03â€.
ğŸ” Conflicting facts	Users occasionally mention inconsistent details (e.g., different car counts).
ğŸ’­ Implicit preferences	Favorites and plans are often implied, not explicitly stated.
ğŸ•“ Inconsistent timestamps	Some entries are misordered or future-dated.
Fixes Used

Removed duplicate messages before embedding.

Normalized date formats for clarity.

When conflicts appeared, prioritized the most recent message.

Prompted the LLM to hedge uncertain facts (e.g., â€œappears to preferâ€¦â€).

ğŸ“¡ API Example
Endpoint:
GET /ask?question=<your-question>

Example:
curl "http://127.0.0.1:8000/ask?question=What are Fatima's favorite restaurants?"


Response:

{
  "answer": "Fatima appears to favor high-end, Michelin-starred restaurants like Le Bernardin, Osteria Francescana, and Alinea."
}

ğŸ§° Local Setup

1ï¸âƒ£ Clone the repo

git clone https://github.com/yashiagar2507/aurora-rag-api.git

cd aurora-rag-api


2ï¸âƒ£ Install dependencies

pip install -r requirements.txt


3ï¸âƒ£ Add your Anthropic API key in .env

ANTHROPIC_API_KEY=sk-ant-api03-xxxxxxxxxxxxxxxx


4ï¸âƒ£ Run the FastAPI server

uvicorn main:app --port 8000

Built by Yashi Agarwal
GitHub: @yashiagar2507

Model: Claude Sonnet 4.5 via Anthropic API
Date: November 2025

